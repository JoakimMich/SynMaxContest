{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from math import cos, asin, sqrt, isnan, radians, sin\n",
    "import utm\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports = pd.read_csv(\"ports.csv\")\n",
    "tracking = pd.read_csv(\"tracking.csv\").drop_duplicates().sort_values(by='datetime', ascending=True)\n",
    "voyages = pd.read_csv(\"voyages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_pattern = []\n",
    "for vessel in voyages.drop_duplicates(subset=['vessel'])['vessel'].values:\n",
    "    if len(voyages[voyages.vessel==vessel]['end_port_id'].unique()) < 3:\n",
    "        dual_pattern.append(vessel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pattern = []\n",
    "second_pattern = []\n",
    "\n",
    "for vessel in voyages.drop_duplicates(subset=['vessel'])['vessel'].values:\n",
    "    voyages_vessel = voyages[voyages.vessel==vessel]\n",
    "    most_common_count = voyages_vessel['end_port_id'].value_counts().values[0]\n",
    "    most_common = voyages_vessel['end_port_id'].value_counts().keys()[0]\n",
    "    second_most_common_count = voyages_vessel['end_port_id'].value_counts().values[1]\n",
    "    latest_port = voyages_vessel.iloc[-1]['end_port_id']\n",
    "    \n",
    "    if most_common == latest_port:\n",
    "        if (len(voyages_vessel) % 2) == 0 and most_common_count == (len(voyages_vessel) / 2):\n",
    "            first_pattern.append(vessel)\n",
    "        elif (len(voyages_vessel) % 2) != 0 and abs((int(len(voyages_vessel))/2) - most_common_count) == 1:\n",
    "            first_pattern.append(vessel)\n",
    "    else:\n",
    "        if (len(voyages_vessel) % 2) == 0 and most_common_count == (len(voyages_vessel) / 2):\n",
    "            second_pattern.append(vessel)\n",
    "        elif (len(voyages_vessel) % 2) != 0 and abs((int(len(voyages_vessel))/2) - most_common_count) == 1:\n",
    "            second_pattern.append(vessel)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports_temp = pd.read_csv(\"ports.csv\").copy()\n",
    "ports_temp.loc[(ports_temp.port==142), 'lat'] = 30.600600\n",
    "ports_temp.loc[(ports_temp.port==142), 'long'] = 122.104500\n",
    "\n",
    "ports_temp.loc[(ports_temp.port==76), 'lat'] = 21.903937\n",
    "ports_temp.loc[(ports_temp.port==76), 'long'] = 113.216557\n",
    "\n",
    "voyages = pd.read_csv(\"voyages.csv\")\n",
    "\n",
    "voyages['previous_begin_port_id_1'] = voyages.groupby(['vessel']).begin_port_id.shift(1)\n",
    "voyages = voyages[voyages['previous_begin_port_id_1'].notna()]\n",
    "voyages['previous_begin_port_id_1'] = voyages['previous_begin_port_id_1'].astype(int)\n",
    "\n",
    "voyages['previous_begin_port_id_2'] = voyages.groupby(['vessel']).previous_begin_port_id_1.shift(1)\n",
    "voyages = voyages[voyages['previous_begin_port_id_2'].notna()]\n",
    "voyages['previous_begin_port_id_2'] = voyages['previous_begin_port_id_2'].astype(int)\n",
    "\n",
    "ports_temp['E'] = [utm.from_latlon(x,y)[0] for x,y in zip(ports_temp['lat'], ports_temp['long'])]\n",
    "ports_temp['N'] = [utm.from_latlon(x,y)[1] for x,y in zip(ports_temp['lat'], ports_temp['long'])]\n",
    "ports_temp['Zone'] = [utm.from_latlon(x,y)[2] for x,y in zip(ports_temp['lat'], ports_temp['long'])]\n",
    "ports_temp['Hemi'] = [ord(utm.from_latlon(x,y)[3].lower())-96 for x,y in zip(ports_temp['lat'], ports_temp['long'])]\n",
    "\n",
    "voyages['E_1'] = [ports_temp[ports_temp.port==x]['E'].values[0] for x in voyages['begin_port_id']]\n",
    "voyages['N_1'] = [ports_temp[ports_temp.port==x]['N'].values[0] for x in voyages['begin_port_id']]\n",
    "voyages['Zone_1'] = [ports_temp[ports_temp.port==x]['Zone'].values[0] for x in voyages['begin_port_id']]\n",
    "voyages['Hemi_1'] = [ports_temp[ports_temp.port==x]['Hemi'].values[0] for x in voyages['begin_port_id']]\n",
    "\n",
    "voyages['E_2'] = [ports_temp[ports_temp.port==x]['E'].values[0] for x in voyages['previous_begin_port_id_1']]\n",
    "voyages['N_2'] = [ports_temp[ports_temp.port==x]['N'].values[0] for x in voyages['previous_begin_port_id_1']]\n",
    "voyages['Zone_2'] = [ports_temp[ports_temp.port==x]['Zone'].values[0] for x in voyages['previous_begin_port_id_1']]\n",
    "voyages['Hemi_2'] = [ports_temp[ports_temp.port==x]['Hemi'].values[0] for x in voyages['previous_begin_port_id_1']]\n",
    "\n",
    "voyages['E_3'] = [ports_temp[ports_temp.port==x]['E'].values[0] for x in voyages['previous_begin_port_id_2']]\n",
    "voyages['N_3'] = [ports_temp[ports_temp.port==x]['N'].values[0] for x in voyages['previous_begin_port_id_2']]\n",
    "voyages['Zone_3'] = [ports_temp[ports_temp.port==x]['Zone'].values[0] for x in voyages['previous_begin_port_id_2']]\n",
    "voyages['Hemi_3'] = [ports_temp[ports_temp.port==x]['Hemi'].values[0] for x in voyages['previous_begin_port_id_2']]\n",
    "\n",
    "\n",
    "voyages.loc[:,'day'] = [datetime.strptime(x , '%Y-%m-%d %H:%M:%S').timetuple().tm_yday for x in voyages['begin_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_1 = voyages[~voyages.vessel.isin(dual_pattern)].copy()\n",
    "X_1 = train_set_1[['E_1', 'N_1', 'Zone_1', 'Hemi_1', 'E_2', 'N_2', 'Zone_2', 'Hemi_2', 'E_3', 'N_3', 'Zone_3', 'Hemi_3']]\n",
    "y_1 = train_set_1['end_port_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40846271423069513\n",
      "{'eta': 0.01, 'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "#X = [X_1, X_2, X_3]\n",
    "#y = [y_1, y_2, y_3]\n",
    "\n",
    "X = [X_1]\n",
    "y = [y_1]\n",
    "\n",
    "eta = [0.01]\n",
    "max_depth = [7]\n",
    "\n",
    "hyperF = dict(eta=eta, max_depth=max_depth)\n",
    "\n",
    "gridF = GridSearchCV(XGBClassifier(eval_metric='mlogloss'), hyperF, cv = StratifiedKFold(n_splits=5, shuffle=True), verbose = 1, n_jobs = -1)\n",
    "model = gridF.fit(X[0], y[0])\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_1, y_1)\n",
    "pickle.dump(model, open('model_xgb.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_most_common(port, most_common, second_most_common):\n",
    "    if port == most_common:\n",
    "        return(second_most_common)\n",
    "    else:\n",
    "        return(most_common)\n",
    "    \n",
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    p = 0.017453292519943295\n",
    "    hav = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2\n",
    "    return 12742 * asin(sqrt(hav))\n",
    "\n",
    "def closest_port(data, v, ports):\n",
    "    pos = min(data, key=lambda p: distance(v['lat'],v['long'],p['lat'],p['long']))\n",
    "    dist = distance(pos['lat'], pos['long'], v['lat'], v['long'])\n",
    "    return (ports[(ports.lat == pos['lat']) & (ports.long == pos['long'])]['port'].values[0], dist)\n",
    "\n",
    "def get_utm(port):\n",
    "    ports_port = ports_temp[ports_temp.port==port]\n",
    "    #ports_temp[ports_temp.port==x]['x'].values[0]\n",
    "    return(ports_port['E'].values[0], ports_port['N'].values[0], ports_port['Zone'].values[0], ports_port['Hemi'].values[0])\n",
    "\n",
    "def model_non_duplicate(model, voyage_compare, E_1, N_1, Zone_1, Hemi_1, E_2, N_2, Zone_2, Hemi_2, E_3, N_3, Zone_3, Hemi_3):\n",
    "    to_predict = [E_1, N_1, Zone_1, Hemi_1, E_2, N_2, Zone_2, Hemi_2, E_3, N_3, Zone_3, Hemi_3]\n",
    "    to_predict = np.array(to_predict).reshape((1,-1))\n",
    "    \n",
    "    voyage_probs = model.predict_proba(to_predict)[0]\n",
    "    voyage_probs = np.argsort(-voyage_probs)\n",
    "    new_voyage = model.classes_[voyage_probs[0]]\n",
    "    \n",
    "    if new_voyage == voyage_compare:\n",
    "        new_voyage = model.classes_[voyage_probs[1]]\n",
    "    \n",
    "    return new_voyage\n",
    "\n",
    "ports_dict = ports[['lat', 'long']].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list = []\n",
    "voyages_new = pd.read_csv('voyages.csv')\n",
    "\n",
    "for vessel in dual_pattern:\n",
    "    tracking_vessel = tracking[tracking.vessel == vessel]\n",
    "    \n",
    "    voyages_vessel = voyages_new[voyages_new.vessel == vessel]\n",
    "    port = voyages_vessel.iloc[-1]['end_port_id']\n",
    "    \n",
    "    two_most_common = voyages_vessel['end_port_id'].value_counts().nlargest(2).keys()\n",
    "    most_common = two_most_common[0]\n",
    "    second_most_common = two_most_common[1]\n",
    "    \n",
    "    voyage_1 = next_most_common(port, most_common, second_most_common)\n",
    "    voyage_2 = next_most_common(voyage_1, most_common, second_most_common)\n",
    "    voyage_3 = next_most_common(voyage_2, most_common, second_most_common)\n",
    "    \n",
    "    predict_list.append({'vessel': vessel, 'begin_port_id': port, 'end_port_id': voyage_1, 'voyage': 1})\n",
    "    predict_list.append({'vessel': vessel, 'begin_port_id': voyage_1, 'end_port_id': voyage_2, 'voyage': 2})\n",
    "    predict_list.append({'vessel': vessel, 'begin_port_id': voyage_2, 'end_port_id': voyage_3, 'voyage': 3})\n",
    "\n",
    "for vessel in voyages.drop_duplicates(subset=['vessel'])['vessel'].values:\n",
    "#for vessel in [131,1]:\n",
    "    if vessel not in dual_pattern:\n",
    "        voyages_vessel = voyages[voyages.vessel == vessel]\n",
    "        \n",
    "        two_most_common = voyages_new[voyages_new.vessel==vessel]['end_port_id'].value_counts().nlargest(2).keys()\n",
    "        most_common = two_most_common[0]\n",
    "        second_most_common = two_most_common[1]\n",
    "    \n",
    "        port_1 = voyages_vessel.iloc[-1]['end_port_id']\n",
    "        port_2 = voyages_vessel.iloc[-1]['begin_port_id']\n",
    "        port_3 = voyages_vessel.iloc[-1]['previous_begin_port_id_1']\n",
    "        (E_1, N_1, Zone_1, Hemi_1) = get_utm(port_1)\n",
    "        (E_2, N_2, Zone_2, Hemi_2) = get_utm(port_2)\n",
    "        (E_3, N_3, Zone_3, Hemi_3) = get_utm(port_3)\n",
    "            \n",
    "        if vessel in first_pattern:\n",
    "            voyage_1 = model_non_duplicate(model, port_1, E_1, N_1, Zone_1, Hemi_1, E_2, N_2, Zone_2, Hemi_2, E_3, N_3, Zone_3, Hemi_3)\n",
    "            voyage_2 = next_most_common(voyage_1, most_common, second_most_common)\n",
    "            (E_4, N_4, Zone_4, Hemi_4) = get_utm(voyage_1)\n",
    "            (E_5, N_5, Zone_5, Hemi_5) = get_utm(voyage_2)\n",
    "            voyage_3 = model_non_duplicate(model, voyage_2, E_5, N_5, Zone_5, Hemi_5, E_4, N_4, Zone_4, Hemi_4, E_1, N_1, Zone_1, Hemi_1)\n",
    "        elif vessel in second_pattern:\n",
    "            voyage_1 = next_most_common(port_1, most_common, second_most_common)\n",
    "            (E_4, N_4, Zone_4, Hemi_4) = get_utm(voyage_1)\n",
    "            voyage_2 = model_non_duplicate(model, voyage_1, E_4, N_4, Zone_4, Hemi_4, E_1, N_1, Zone_1, Hemi_1, E_2, N_2, Zone_2, Hemi_2)\n",
    "            voyage_3 = next_most_common(voyage_2, most_common, second_most_common)\n",
    "        else:\n",
    "            voyage_1 = model_non_duplicate(model, port_1, E_1, N_1, Zone_1, Hemi_1, E_2, N_2, Zone_2, Hemi_2, E_3, N_3, Zone_3, Hemi_3)\n",
    "            (E_4, N_4, Zone_4, Hemi_4) = get_utm(voyage_1)\n",
    "            voyage_2 = model_non_duplicate(model, voyage_1, E_4, N_4, Zone_4, Hemi_4, E_1, N_1, Zone_1, Hemi_1, E_2, N_2, Zone_2, Hemi_2)\n",
    "            (E_5, N_5, Zone_5, Hemi_5) = get_utm(voyage_2)\n",
    "            voyage_3 = model_non_duplicate(model, voyage_2, E_5, N_5, Zone_5, Hemi_5, E_4, N_4, Zone_4, Hemi_4, E_1, N_1, Zone_1, Hemi_1)\n",
    "                    \n",
    "        if voyage_1 == port_1:\n",
    "            print(\"Error1\")\n",
    "            \n",
    "        if voyage_1 == voyage_2:\n",
    "            print(\"Error2\")\n",
    "    \n",
    "        if voyage_2 == voyage_3:\n",
    "            print(\"Error3\")\n",
    "            \n",
    "        predict_list.append({'vessel': vessel, 'begin_port_id': port_1, 'end_port_id': voyage_1, 'voyage': 1})\n",
    "        predict_list.append({'vessel': vessel, 'begin_port_id': voyage_1, 'end_port_id': voyage_2, 'voyage': 2})\n",
    "        predict_list.append({'vessel': vessel, 'begin_port_id': voyage_2, 'end_port_id': voyage_3, 'voyage': 3})\n",
    "\n",
    "predict = pd.DataFrame(predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = predict.sort_values(['vessel', 'voyage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.to_csv('predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
